{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im going to follow the same approach most of the notebooks I've seen here. I'll see what they are trying to do and their approach. Maybe learn a couple of things and improve on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import glob             # file pattern matching\n",
    "import numpy as np        # numerical operations\n",
    "import pandas as pd         # data manipulation\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning using scikit-learn for model training and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, brier_score_loss, mean_squared_error, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression  # For probability calibration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "Most notebooks appear to be concatenating all the notebooks into a single csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(data_path)\n",
    "data = {p.split('/')[-1].split('.')[0]: pd.read_csv(p, encoding='latin-1') for p in files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the mens and womens teams and their spellings\n",
    "# then merge into a single dataframe of teams\n",
    "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates men's and women's regular season and NCAA tournament for compact and detailed results.\n",
    "season_cresults = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']])\n",
    "season_dresults = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']])\n",
    "tourney_cresults = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']])\n",
    "tourney_dresults = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seeds data frame with the mens and womens seeds\n",
    "# and then create a dictionary of seeds\n",
    "# The dictionary is indexed by the season and team id\n",
    "seeds_df = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "seeds = {'_'.join(map(str, [int(k1), k2])): int(v[1:3]) for k1, v, k2 in seeds_df[['Season', 'Seed', 'TeamID']].values}\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission column into the data\n",
    "sub = data['SampleSubmissionStage1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten the categories names\n",
    "season_cresults['ST'] = 'S'\n",
    "season_dresults['ST'] = 'S'\n",
    "tourney_cresults['ST'] = 'T'\n",
    "tourney_dresults['ST'] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a games dataframe\n",
    "games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "games['WLoc'] = games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for all the games statistics and diffs\n",
    "games['ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']] + sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
    "games['IDTeams'] = games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
    "games['Team1'] = games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[0], axis=1)\n",
    "games['Team2'] = games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[1], axis=1)\n",
    "games['IDTeam1'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "games['IDTeam2'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "games['Team1Seed'] = games['IDTeam1'].map(seeds).fillna(0)\n",
    "games['Team2Seed'] = games['IDTeam2'].map(seeds).fillna(0)\n",
    "games['ScoreDiff'] = games['WScore'] - games['LScore']\n",
    "games['Pred'] = games.apply(lambda r: 1.0 if sorted([r['WTeamID'], r['LTeamID']])[0] == r['WTeamID'] else 0.0, axis=1)\n",
    "games['ScoreDiffNorm'] = games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0.0 else r['ScoreDiff'], axis=1)\n",
    "games['SeedDiff'] = games['Team1Seed'] - games['Team2Seed']\n",
    "# fillna\n",
    "games = games.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create aggregated statistics\n",
    "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n",
    "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "gb = games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the tourney games\n",
    "tourney_games = games[games['ST'] == 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the game states to the submission dataframe\n",
    "sub['WLoc'] = 3\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0]).astype(int)\n",
    "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
    "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
    "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
    "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
    "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed']\n",
    "sub = sub.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the aggregated statistics into the games and submission dataframes\n",
    "games = pd.merge(games, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the columns that are not needed\n",
    "# and create a list of columns to be used\n",
    "exclude_cols = ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col\n",
    "col = [c for c in games.columns if c not in exclude_cols]\n",
    "print(\"Data loading and preprocessing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
